{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python388jvsc74a57bd08f7a9caefe3fbe01c4aa0205e6cc1c36763ed3d41b234746df90d0099aaa4109",
   "display_name": "Python 3.8.8 64-bit ('tf': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import logging\n",
    "import os\n",
    "import glob\n",
    "import json\n",
    "import re\n",
    "import random\n",
    "import textwrap\n",
    "from termcolor import colored\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as mlt\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "from transformers import T5Tokenizer,T5ForConditionalGeneration,AdamW,get_linear_schedule_with_warmup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Global seed set to 42\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "pl.seed_everything(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_data(path):\n",
    "    with path.open() as f:\n",
    "        data=json.load(f)\n",
    "    \n",
    "    questions=data['data'][0]['paragraphs']\n",
    "    rows=list()\n",
    "\n",
    "    for question in questions:\n",
    "        context=question['context']\n",
    "        for qa in question['qas']:\n",
    "            question_=qa['question']\n",
    "            answers=qa['answers']\n",
    "            for answer in answers:\n",
    "                answer_text=answer['text']\n",
    "                answer_start=answer['answer_start']\n",
    "                answer_end=answer_start+len(answer_text)\n",
    "\n",
    "                rows.append({\n",
    "                    'question':question_,\n",
    "                    'context':context,\n",
    "                    'answer_text':answer_text,\n",
    "                    'answer_start':answer_start,\n",
    "                    'answer_end':answer_end\n",
    "                })\n",
    "    return pd.DataFrame(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                            question  \\\n",
       "0  What is the inheritance pattern of Li–Fraumeni...   \n",
       "1  What is the inheritance pattern of Li–Fraumeni...   \n",
       "2    Which type of lung cancer is afatinib used for?   \n",
       "3  Which hormone abnormalities are characteristic...   \n",
       "4  Which hormone abnormalities are characteristic...   \n",
       "\n",
       "                                             context         answer_text  \\\n",
       "0  Balanced t(11;15)(q23;q15) in a TP53+/+ breast...  autosomal dominant   \n",
       "1  Genetic modeling of Li-Fraumeni syndrome in ze...  autosomal dominant   \n",
       "2  Clinical perspective of afatinib in non-small ...   EGFR-mutant NSCLC   \n",
       "3  DOCA sensitive pendrin expression in kidney, h...             thyroid   \n",
       "4  Clinical and molecular characteristics of Pend...             thyroid   \n",
       "\n",
       "   answer_start  answer_end  \n",
       "0           213         231  \n",
       "1           105         123  \n",
       "2          1203        1220  \n",
       "3           419         426  \n",
       "4           705         712  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>question</th>\n      <th>context</th>\n      <th>answer_text</th>\n      <th>answer_start</th>\n      <th>answer_end</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>What is the inheritance pattern of Li–Fraumeni...</td>\n      <td>Balanced t(11;15)(q23;q15) in a TP53+/+ breast...</td>\n      <td>autosomal dominant</td>\n      <td>213</td>\n      <td>231</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>What is the inheritance pattern of Li–Fraumeni...</td>\n      <td>Genetic modeling of Li-Fraumeni syndrome in ze...</td>\n      <td>autosomal dominant</td>\n      <td>105</td>\n      <td>123</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Which type of lung cancer is afatinib used for?</td>\n      <td>Clinical perspective of afatinib in non-small ...</td>\n      <td>EGFR-mutant NSCLC</td>\n      <td>1203</td>\n      <td>1220</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Which hormone abnormalities are characteristic...</td>\n      <td>DOCA sensitive pendrin expression in kidney, h...</td>\n      <td>thyroid</td>\n      <td>419</td>\n      <td>426</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Which hormone abnormalities are characteristic...</td>\n      <td>Clinical and molecular characteristics of Pend...</td>\n      <td>thyroid</td>\n      <td>705</td>\n      <td>712</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "extract_data(Path('data/BioASQ/BioASQ-train-factoid-4b.json')).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                            question  \\\n",
       "0  What is the inheritance pattern of Li–Fraumeni...   \n",
       "1  What is the inheritance pattern of Li–Fraumeni...   \n",
       "2    Which type of lung cancer is afatinib used for?   \n",
       "3  Which hormone abnormalities are characteristic...   \n",
       "4  Which hormone abnormalities are characteristic...   \n",
       "\n",
       "                                             context         answer_text  \\\n",
       "0  Balanced t(11;15)(q23;q15) in a TP53+/+ breast...  autosomal dominant   \n",
       "1  Genetic modeling of Li-Fraumeni syndrome in ze...  autosomal dominant   \n",
       "2  Clinical perspective of afatinib in non-small ...   EGFR-mutant NSCLC   \n",
       "3  DOCA sensitive pendrin expression in kidney, h...             thyroid   \n",
       "4  Clinical and molecular characteristics of Pend...             thyroid   \n",
       "\n",
       "   answer_start  answer_end  \n",
       "0           213         231  \n",
       "1           105         123  \n",
       "2          1203        1220  \n",
       "3           419         426  \n",
       "4           705         712  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>question</th>\n      <th>context</th>\n      <th>answer_text</th>\n      <th>answer_start</th>\n      <th>answer_end</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>What is the inheritance pattern of Li–Fraumeni...</td>\n      <td>Balanced t(11;15)(q23;q15) in a TP53+/+ breast...</td>\n      <td>autosomal dominant</td>\n      <td>213</td>\n      <td>231</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>What is the inheritance pattern of Li–Fraumeni...</td>\n      <td>Genetic modeling of Li-Fraumeni syndrome in ze...</td>\n      <td>autosomal dominant</td>\n      <td>105</td>\n      <td>123</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Which type of lung cancer is afatinib used for?</td>\n      <td>Clinical perspective of afatinib in non-small ...</td>\n      <td>EGFR-mutant NSCLC</td>\n      <td>1203</td>\n      <td>1220</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Which hormone abnormalities are characteristic...</td>\n      <td>DOCA sensitive pendrin expression in kidney, h...</td>\n      <td>thyroid</td>\n      <td>419</td>\n      <td>426</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Which hormone abnormalities are characteristic...</td>\n      <td>Clinical and molecular characteristics of Pend...</td>\n      <td>thyroid</td>\n      <td>705</td>\n      <td>712</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "paths=sorted(list(Path('data/BioASQ').glob(\"BioASQ-train-*\")))\n",
    "ds=list()\n",
    "for path in paths:\n",
    "    ds.append(extract_data(path))\n",
    "df=pd.concat(ds)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer=T5Tokenizer.from_pretrained('t5-base',cache_dir='cache/t5-base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BioQADataset(Dataset):\n",
    "\n",
    "    def __init__(self,data,tokenizer,encoder_maxlen=396,decoder_maxlen=32):\n",
    "        self.data=data\n",
    "        self.tokenizer=tokenizer\n",
    "        self.encoder_maxlen=encoder_maxlen\n",
    "        self.decoder_maxlen=decoder_maxlen\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self,index):\n",
    "        instance=self.data.iloc[index]\n",
    "\n",
    "        source_encoding=tokenizer(instance['question'],instance['context'],max_length=self.encoder_maxlen,padding='max_length',truncation='only_second',return_attention_mask=True,\n",
    "            add_special_tokens=True,return_tensors='pt')\n",
    "        target_encoding=tokenizer(instance['answer_text'],max_length=self.decoder_maxlen,padding='max_length',truncation=True,return_attention_mask=True,\n",
    "            add_special_tokens=True,return_tensors='pt')\n",
    "\n",
    "        labels=target_encoding['input_ids']\n",
    "        labels[labels==0]=-100\n",
    "\n",
    "        return dict(question=instance['question'],context=instance['context'],answer_text=instance['answer_text'],input_ids=source_encoding['input_ids'],\n",
    "            attention_mask=source_encoding['attention_mask'],labels=labels.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df,val_df=train_test_split(df,test_size=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BioQADataModule(pl.LightningDataModule):\n",
    "\n",
    "    def __init__(self,train_df,test_df,tokenizer,encoder_maxlen=396,decoder_maxlen=32,batch_size=8):\n",
    "        super().__init__()\n",
    "        self.batch_size=batch_size\n",
    "        self.train_df=train_df\n",
    "        self.test_df=test_df\n",
    "        self.tokenizer=tokenizer\n",
    "        self.encoder_maxlen=encoder_maxlen\n",
    "        self.decoder_maxlen=decoder_maxlen\n",
    "\n",
    "    def setup(self):\n",
    "        self.train_ds=BioQADataset(self.train_df,self.tokenizer,self.encoder_maxlen,self.decoder_maxlen)\n",
    "        self.test_ds=BioQADataset(self.test_df,self.tokenizer,self.encoder_maxlen,self.decoder_maxlen)\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.train_ds,batch_size=8,shuffle=True,num_workers=4)\n",
    "    \n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.test_ds,batch_size=1,shuffle=True,num_workers=4)\n",
    "    \n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(self.test_ds,batch_size=1,shuffle=True,num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE=8\n",
    "EPOCHS=6\n",
    "\n",
    "data_module=BioQADataModule(train_df,val_df,tokenizer,batch_size=BATCH_SIZE)\n",
    "data_module.setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=T5ForConditionalGeneration.from_pretrained('t5-base',cache_dir='model_cache/t5-base',return_dict=True)"
   ]
  },
  {
   "source": [
    "# Test"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'Ich bin ein Junge.'"
      ]
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "input_ids=tokenizer(\"translate English to German: I am a boy.\",return_tensors='pt').input_ids\n",
    "generated_ids=model.generate(input_ids)\n",
    "preds=[tokenizer.decode(id,skip_special_tokens=True,clean_up_tokenization_spaces=True) for id in generated_ids]\n",
    "translated_text=\"\".join(preds)\n",
    "translated_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'sunflowers were domesticated 3000–5000 years ago by Native Americans. they were'"
      ]
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "source": [
    "text=\"\"\"\n",
    "Sunflowers are thought to have been domesticated 3000–5000 years ago by Native Americans who would use them primarily as a source for edible seeds. They were then introduced to Europe in the early 16th century and made their way to Russia. In Russia, where oilseed cultivators were located, these flowers were developed and grown on an industrial scale. Russia then reintroduced this oilseed cultivation process to North America in the mid-20th century; North America began their commercial era of sunflower production and breeding.[12] New breeds of the Helianthus spp. began to become more prominent in new geographical areas.\n",
    "\n",
    "This species' geographical history accounts for its evolutionary history, with its levels of genetic variation across its gene pool increasing as new hybrids are created both for commercial use and in the wild. Subsequent to this, sunflower species are also experiencing the bottle neck effect in their gene pool as a result of selective breeding for industrial use.[12]\n",
    "\"\"\"\n",
    "text='summarize: '+ text\n",
    "input_ids=tokenizer(text,return_tensors='pt').input_ids\n",
    "generated_ids=model.generate(input_ids)\n",
    "preds=[tokenizer.decode(id,skip_special_tokens=True,clean_up_tokenization_spaces=True) for id in generated_ids]\n",
    "summarized_text=\"\".join(preds)\n",
    "summarized_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BioQAT5Model(pl.LightningModule):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.model=T5ForConditionalGeneration.from_pretrained('t5-base',cache_dir='model_cache/t5-base',return_dict=True)\n",
    "    \n",
    "    def forward(self,input_ids,attention_mask,labels=None):\n",
    "        output=self.model(input_ids=input_ids,attention_mask=attention_mask,labels=labels)\n",
    "        return output.loss,output.logits\n",
    "    \n",
    "    def training_step(self,batch,batch_idx):\n",
    "        input_ids=batch['input_ids']\n",
    "        attention_mask=batch['attention_mask']\n",
    "        labels=batch['labels']\n",
    "        loss,output=self(input_ids,attention_mask,labels)\n",
    "        self.log('train_loss',loss,prog_bar=True,logger=True)\n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self,batch,batch_idx):\n",
    "        input_ids=batch['input_ids']\n",
    "        attention_mask=batch['attention_mask']\n",
    "        labels=batch['labels']\n",
    "        loss,output=self(input_ids,attention_mask,labels)\n",
    "        self.log('val_loss',loss,prog_bar=True,logger=True)\n",
    "        return loss\n",
    "\n",
    "    def test_step(self,batch,batch_idx):\n",
    "        input_ids=batch['input_ids']\n",
    "        attention_mask=batch['attention_mask']\n",
    "        labels=batch['labels']\n",
    "        loss,output=self(input_ids,attention_mask,labels)\n",
    "        self.log('test_loss',loss,prog_bar=True,logger=True)\n",
    "        return loss\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        return AdamW(self.parameters(),lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=BioQAT5Model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_checkpoint=pl.callbacks.model_checkpoint.ModelCheckpoint('checkpoints','pt_t5_1',save_top_k=1,verbose=True,monitor='val_loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n"
     ]
    }
   ],
   "source": [
    "trainer=pl.Trainer(checkpoint_callback=model_checkpoint,max_epochs=EPOCHS,gpus=1,progress_bar_refresh_rate=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "ERROR: Timed out waiting for TensorBoard to start. It may still be running as pid 11020."
     },
     "metadata": {}
    }
   ],
   "source": [
    "%tensorboard --logdir ./logs/ptl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name  | Type                       | Params\n",
      "-----------------------------------------------------\n",
      "0 | model | T5ForConditionalGeneration | 222 M \n",
      "-----------------------------------------------------\n",
      "222 M     Trainable params\n",
      "0         Non-trainable params\n",
      "222 M     Total params\n",
      "891.614   Total estimated model params size (MB)\n",
      "Validation sanity check: 0it [00:00, ?it/s]"
     ]
    },
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'test_ds' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-29-b9cdaa88efa7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdata_module\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mF:\\anacondapython\\envs\\tf\\lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, model, train_dataloader, val_dataloaders, datamodule)\u001b[0m\n\u001b[0;32m    456\u001b[0m         )\n\u001b[0;32m    457\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 458\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_run\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    459\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    460\u001b[0m         \u001b[1;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstopped\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\anacondapython\\envs\\tf\\lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, model)\u001b[0m\n\u001b[0;32m    754\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    755\u001b[0m         \u001b[1;31m# dispatch `start_training` or `start_evaluating` or `start_predicting`\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 756\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    757\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    758\u001b[0m         \u001b[1;31m# plugin will finalized fitting (e.g. ddp_spawn will load trained model)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\anacondapython\\envs\\tf\\lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py\u001b[0m in \u001b[0;36mdispatch\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    795\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maccelerator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstart_predicting\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    796\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 797\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maccelerator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstart_training\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    798\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    799\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mrun_stage\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\anacondapython\\envs\\tf\\lib\\site-packages\\pytorch_lightning\\accelerators\\accelerator.py\u001b[0m in \u001b[0;36mstart_training\u001b[1;34m(self, trainer)\u001b[0m\n\u001b[0;32m     94\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     95\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mstart_training\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'pl.Trainer'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 96\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtraining_type_plugin\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstart_training\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     97\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     98\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mstart_evaluating\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'pl.Trainer'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\anacondapython\\envs\\tf\\lib\\site-packages\\pytorch_lightning\\plugins\\training_type\\training_type_plugin.py\u001b[0m in \u001b[0;36mstart_training\u001b[1;34m(self, trainer)\u001b[0m\n\u001b[0;32m    142\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mstart_training\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'pl.Trainer'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    143\u001b[0m         \u001b[1;31m# double dispatch to initiate the training loop\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 144\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_results\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_stage\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    145\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    146\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mstart_evaluating\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'pl.Trainer'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\anacondapython\\envs\\tf\\lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py\u001b[0m in \u001b[0;36mrun_stage\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    805\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredicting\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    806\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_predict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 807\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_train\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    808\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    809\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_pre_training_routine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\anacondapython\\envs\\tf\\lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py\u001b[0m in \u001b[0;36mrun_train\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    840\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprogress_bar_callback\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdisable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    841\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 842\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_sanity_check\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlightning_module\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    843\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    844\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcheckpoint_connector\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhas_trained\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\anacondapython\\envs\\tf\\lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py\u001b[0m in \u001b[0;36mrun_sanity_check\u001b[1;34m(self, ref_model)\u001b[0m\n\u001b[0;32m   1105\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1106\u001b[0m             \u001b[1;31m# run eval step\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1107\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_evaluation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1108\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1109\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_sanity_check_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\anacondapython\\envs\\tf\\lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py\u001b[0m in \u001b[0;36mrun_evaluation\u001b[1;34m(self, on_epoch)\u001b[0m\n\u001b[0;32m    918\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    919\u001b[0m         \u001b[1;31m# prepare dataloaders\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 920\u001b[1;33m         \u001b[0mdataloaders\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_batches\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluation_loop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_evaluation_dataloaders\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    921\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    922\u001b[0m         \u001b[1;31m# check if we want to skip this evaluation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\anacondapython\\envs\\tf\\lib\\site-packages\\pytorch_lightning\\trainer\\evaluation_loop.py\u001b[0m in \u001b[0;36mget_evaluation_dataloaders\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[1;31m# val\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mval_dataloaders\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreload_dataloaders_every_epoch\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreset_val_dataloader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msanity_checking\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m                 self.trainer.num_sanity_val_batches = [\n",
      "\u001b[1;32mF:\\anacondapython\\envs\\tf\\lib\\site-packages\\pytorch_lightning\\trainer\\data_loading.py\u001b[0m in \u001b[0;36mreset_val_dataloader\u001b[1;34m(self, model)\u001b[0m\n\u001b[0;32m    407\u001b[0m         \u001b[0mhas_step\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mis_overridden\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'validation_step'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    408\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mhas_loader\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mhas_step\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 409\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnum_val_batches\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mval_dataloaders\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reset_eval_dataloader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'val'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    410\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    411\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mreset_test_dataloader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\anacondapython\\envs\\tf\\lib\\site-packages\\pytorch_lightning\\trainer\\data_loading.py\u001b[0m in \u001b[0;36m_reset_eval_dataloader\u001b[1;34m(self, model, mode)\u001b[0m\n\u001b[0;32m    316\u001b[0m         \u001b[1;31m# always get the loaders first so we can count how many there are\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    317\u001b[0m         \u001b[0mloader_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34mf'{mode}_dataloader'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 318\u001b[1;33m         \u001b[0mdataloaders\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrequest_dataloader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    319\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    320\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataloaders\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\anacondapython\\envs\\tf\\lib\\site-packages\\pytorch_lightning\\trainer\\data_loading.py\u001b[0m in \u001b[0;36mrequest_dataloader\u001b[1;34m(self, model, stage)\u001b[0m\n\u001b[0;32m    440\u001b[0m         \"\"\"\n\u001b[0;32m    441\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcall_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"on_{stage}_dataloader\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 442\u001b[1;33m         \u001b[0mdataloader\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mDataLoader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34mf'{stage}_dataloader'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    443\u001b[0m         \u001b[0mdataloader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_flatten_dl_only\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    444\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maccelerator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbarrier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'get_dataloaders'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-9-e8b4180ad296>\u001b[0m in \u001b[0;36mval_dataloader\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mval_dataloader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_ds\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnum_workers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mtest_dataloader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'test_ds' is not defined"
     ]
    }
   ],
   "source": [
    "trainer.fit(model,data_module)"
   ]
  }
 ]
}